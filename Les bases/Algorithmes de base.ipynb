{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87938e4a",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/ramjasmaurya/poem-classification-nlp?select=Poem_classification+-+train_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0c6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812bc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Essai.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397031cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1479861",
   "metadata": {},
   "source": [
    "> ### Suppression des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457bc267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd85500",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79901b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361f15c",
   "metadata": {},
   "source": [
    "> ### Suppression des valeurs manquantes (NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c059629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN(s) (data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NaN(s) (data)\n",
       "Text                  0\n",
       "Language              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(data.isna().sum(), columns=['NaN(s) (data)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70c403dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686a90db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN(s) (data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NaN(s) (data)\n",
       "Text                  0\n",
       "Language              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(data.isna().sum(), columns=['NaN(s) (data)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c87b33",
   "metadata": {},
   "source": [
    "># Creation du dataset English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ac1acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_data = data[data['Language'] == 'English'].reset_index(drop = True)\n",
    "english_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39219025",
   "metadata": {},
   "source": [
    "> # Bag-Of-Words\n",
    ">\n",
    ">C'est une méthode consiste principalement à nettoyer les données textuelles à notre disposition d’une certaine manière afin de pouvoir ensuite les fournir en entrée de modèles d’apprentissage automatique \n",
    "\n",
    ">Un bag-of-words est une représentation du texte qui décrit la présence de mots dans un document. Cela implique deux choses :\n",
    ">\n",
    ">un vocabulaire de mots connus,\n",
    ">une mesure de la présence des mots connus.\n",
    ">\n",
    ">\n",
    ">Le premier point lié au vocabulaire repose sur des étapes de :\n",
    ">\n",
    ">normalisation du texte\n",
    ">tokenization\n",
    ">suppression des stopwords\n",
    ">lemmatization (ou stemming)\n",
    ">Le second point consacrée à la mesure peut être calculé de plusieurs manières différentes :\n",
    ">\n",
    ">le comptage (compter le nombre de fois que chaque mot apparaît dans un document),\n",
    ">les fréquences (calculer la fréquence à laquelle chaque mot apparaît dans un document parmi tous les mots du document. La métrique la plus connue étant TF-IDF,\n",
    ">le hachage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf13d29",
   "metadata": {},
   "source": [
    "># Stopwords\n",
    ">\n",
    ">Les stopwords, ou mots vides en français, désignent les mots qui n’apporte pas de valeur dans la compréhension d’un texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e33175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/emilienbonhomme/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a4a29b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words ('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6113cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_data['NoStopwords'] = english_data['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (english_stop_words)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51dd1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text           Positive results show that a certain class of ...\n",
      "NoStopwords    Positive results show certain class functions ...\n",
      "Name: 833, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"{english_data.iloc[833,[0,2]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106a6d5",
   "metadata": {},
   "source": [
    "># Count Vectorizer\n",
    ">\n",
    ">C'est une fonction qui va découper (via expression régulière) la phrase. Ici nous allons créer un vocabulaire à partir de la colonne Description et « tokenizer » toutes les colonnes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa746a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800    It shifted focus away from the symbolic approa...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_vectorized_data = english_data.iloc[[800],0]\n",
    "english_vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5721847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f96113a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "828a5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = vectorizer.fit_transform(english_vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6943be22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>approaches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borrowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inherited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shifted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>symbolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>toward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0            ai\n",
       "1           and\n",
       "2    approaches\n",
       "3          away\n",
       "4      borrowed\n",
       "5         focus\n",
       "6          from\n",
       "7           had\n",
       "8     inherited\n",
       "9            it\n",
       "10      methods\n",
       "11       models\n",
       "12  probability\n",
       "13      shifted\n",
       "14   statistics\n",
       "15     symbolic\n",
       "16          the\n",
       "17       theory\n",
       "18       toward"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34589e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a10801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it': 9, 'shifted': 13, 'focus': 5, 'away': 3, 'from': 6, 'the': 16, 'symbolic': 15, 'approaches': 2, 'had': 7, 'inherited': 8, 'ai': 0, 'and': 1, 'toward': 18, 'methods': 10, 'models': 11, 'borrowed': 4, 'statistics': 14, 'probability': 12, 'theory': 17}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7239d9",
   "metadata": {},
   "source": [
    "># TF-IDF\n",
    ">\n",
    ">c'est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes. Cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document, relativement à une collection ou un corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c118a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800    It shifted focus away from the symbolic approa...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_tfidf_data = english_data.iloc[[800],0]\n",
    "english_tfidf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3064c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc61af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5a62fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = tfidf.fit_transform(english_tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f67b0cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>approaches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borrowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inherited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shifted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>symbolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>toward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0            ai\n",
       "1           and\n",
       "2    approaches\n",
       "3          away\n",
       "4      borrowed\n",
       "5         focus\n",
       "6          from\n",
       "7           had\n",
       "8     inherited\n",
       "9            it\n",
       "10      methods\n",
       "11       models\n",
       "12  probability\n",
       "13      shifted\n",
       "14   statistics\n",
       "15     symbolic\n",
       "16          the\n",
       "17       theory\n",
       "18       toward"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "098d8f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16222142, 0.48666426, 0.16222142, 0.16222142, 0.16222142,\n",
       "        0.16222142, 0.48666426, 0.16222142, 0.16222142, 0.32444284,\n",
       "        0.16222142, 0.16222142, 0.16222142, 0.16222142, 0.16222142,\n",
       "        0.16222142, 0.16222142, 0.16222142, 0.16222142]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "105b2f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it': 9, 'shifted': 13, 'focus': 5, 'away': 3, 'from': 6, 'the': 16, 'symbolic': 15, 'approaches': 2, 'had': 7, 'inherited': 8, 'ai': 0, 'and': 1, 'toward': 18, 'methods': 10, 'models': 11, 'borrowed': 4, 'statistics': 14, 'probability': 12, 'theory': 17}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf41e4d",
   "metadata": {},
   "source": [
    "># Tokenisation\n",
    ">\n",
    ">La tokenisation cherche à transformer un texte en une série de tokens individuels. Dans l’idée, chaque token représente un mot, et identifier des mots semble être une tâche relativement simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87e6e467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probability theory.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_tokenized_data = english_data.iloc[800,0]\n",
    "english_tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a8de5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e8a8545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'shifted',\n",
       " 'focus',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'symbolic',\n",
       " 'approaches',\n",
       " 'it',\n",
       " 'had',\n",
       " 'inherited',\n",
       " 'from',\n",
       " 'AI',\n",
       " ',',\n",
       " 'and',\n",
       " 'toward',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'models',\n",
       " 'borrowed',\n",
       " 'from',\n",
       " 'statistics',\n",
       " 'and',\n",
       " 'probability',\n",
       " 'theory',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(english_tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e36d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'shifted',\n",
       " 'focus',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'symbolic',\n",
       " 'approaches',\n",
       " 'it',\n",
       " 'had',\n",
       " 'inherited',\n",
       " 'from',\n",
       " 'AI',\n",
       " ',',\n",
       " 'and',\n",
       " 'toward',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'models',\n",
       " 'borrowed',\n",
       " 'from',\n",
       " 'statistics',\n",
       " 'and',\n",
       " 'probability',\n",
       " 'theory',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_tokenized_data = wordpunct_tokenize(english_tokenized_data)\n",
    "english_tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e81f4f5",
   "metadata": {},
   "source": [
    "> # FreqDist\n",
    ">\n",
    ">Il peut être intéressant d’avoir la fréquence de distribution des valeurs.\n",
    ">\n",
    ">Cette fonction renvoit un Tableau a deux dimensions dans lequel on trouve chaque valeur du corpus avec sa fréquence de distribution. A titre d’exemple, le mot \"from est placé 3 fois dans le texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77bae566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probability theory.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_freq_data = english_data.iloc[800,0]\n",
    "english_freq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b8c888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d119cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ea2ef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'from': 3, 'and': 3, 'it': 2, 'shifted': 1, 'focus': 1, 'away': 1, 'the': 1, 'symbolic': 1, 'approaches': 1, 'had': 1, ...})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(word.lower() for word in word_tokenize(english_freq_data))\n",
    "fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b354a",
   "metadata": {},
   "source": [
    "># Stemming ou Stemmatisation et Lemmatisation\n",
    "\n",
    ">Le stemming (racinisation en français) vise à garder la racine du mot, c’est à dire le tronquer de toute déclinaison, accord (flexions) et dérivations. Quand il est fait automatiquement (en français et anglais en tout cas je dirais), il consiste la plupart du temps à enlever une partie de la fin du terme, quitte à en enlever trop ou pas assez.\n",
    "\n",
    ">La lemmatisation, consiste à ramener un terme, quels que soient ses accords, déclinaisons, etc. à sa forme la plus simple (pour le français infinitif/masculin-singulier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17cfcf8",
   "metadata": {},
   "source": [
    ">### Porter_Stemmer vs Snowball_Stemmer vs Lancaster_Stemmer vs Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ffb0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5a3fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cb03242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL            PORTER              SNOWBALL            LANCASTER           LEMMATIZER\n",
      "It                  it                  it                  it                  It                  \n",
      "shifted             shift               shift               shift               shifted             \n",
      "focus               focu                focus               foc                 focus               \n",
      "away                away                away                away                away                \n",
      "from                from                from                from                from                \n",
      "the                 the                 the                 the                 the                 \n",
      "symbolic            symbol              symbol              symbol              symbolic            \n",
      "approaches          approach            approach            approach            approach            \n",
      "it                  it                  it                  it                  it                  \n",
      "had                 had                 had                 had                 had                 \n",
      "inherited           inherit             inherit             inherit             inherited           \n",
      "from                from                from                from                from                \n",
      "AI                  ai                  ai                  ai                  AI                  \n",
      ",                   ,                   ,                   ,                   ,                   \n",
      "and                 and                 and                 and                 and                 \n",
      "toward              toward              toward              toward              toward              \n",
      "methods             method              method              method              method              \n",
      "and                 and                 and                 and                 and                 \n",
      "models              model               model               model               model               \n",
      "borrowed            borrow              borrow              borrow              borrowed            \n",
      "from                from                from                from                from                \n",
      "statistics          statist             statist             stat                statistic           \n",
      "and                 and                 and                 and                 and                 \n",
      "probability         probabl             probabl             prob                probability         \n",
      "theory              theori              theori              the                 theory              \n",
      ".                   .                   .                   .                   .                   \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'ORIGINAL': <20}{'PORTER': <20}{'SNOWBALL': <20}{'LANCASTER': <20}{'LEMMATIZER'}\")\n",
    "for w in word_tokenize(english_data.iloc[800,0]):\n",
    "    print(f\"{w: <20}{porter.stem(w): <20}{snowball.stem(w): <20}{lancaster.stem(w): <20}{lemmatizer.lemmatize(w): <20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646507ee",
   "metadata": {},
   "source": [
    "># N-Grams\n",
    ">\n",
    ">C'est des sequences de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ebc501b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832      There are two kinds of time complexity results.\n",
       "833    Positive results show that a certain class of ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_ngrams_data = english_data.iloc[832:834,0]\n",
    "english_ngrams_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ae18fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6acff839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('There', 'are', 'two')\n",
      "('are', 'two', 'kinds')\n",
      "('two', 'kinds', 'of')\n",
      "('kinds', 'of', 'time')\n",
      "('of', 'time', 'complexity')\n",
      "('time', 'complexity', 'results.')\n",
      "\n",
      "\n",
      "('Positive', 'results', 'show')\n",
      "('results', 'show', 'that')\n",
      "('show', 'that', 'a')\n",
      "('that', 'a', 'certain')\n",
      "('a', 'certain', 'class')\n",
      "('certain', 'class', 'of')\n",
      "('class', 'of', 'functions')\n",
      "('of', 'functions', 'can')\n",
      "('functions', 'can', 'be')\n",
      "('can', 'be', 'learned')\n",
      "('be', 'learned', 'in')\n",
      "('learned', 'in', 'polynomial')\n",
      "('in', 'polynomial', 'time.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in english_ngrams_data:\n",
    "    n_grams = ngrams(sentence.split(), 3)\n",
    "    for grams in n_grams:\n",
    "        print (grams)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78975d",
   "metadata": {},
   "source": [
    "> # Part-Of-Speech Tag (POS Tag)\n",
    ">\n",
    ">POS tagging (part-of-speech tagging) en anglais) est le processus qui consiste à associer aux mots d'un texte les informations grammaticales correspondantes comme la partie du discours, le genre, le nombre, etc. à l'aide d'un outil informatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "528f208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5cb4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd599b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832      There are two kinds of time complexity results.\n",
       "833    Positive results show that a certain class of ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_pos_data = english_data.iloc[832:834,0]\n",
    "english_pos_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "742db9dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There | PRON\n",
      "are | VERB\n",
      "two | NUM\n",
      "kinds | NOUN\n",
      "of | ADP\n",
      "time | NOUN\n",
      "complexity | NOUN\n",
      "results | NOUN\n",
      ". | PUNCT\n",
      "\n",
      "\n",
      "Positive | ADJ\n",
      "results | NOUN\n",
      "show | VERB\n",
      "that | SCONJ\n",
      "a | DET\n",
      "certain | ADJ\n",
      "class | NOUN\n",
      "of | ADP\n",
      "functions | NOUN\n",
      "can | AUX\n",
      "be | AUX\n",
      "learned | VERB\n",
      "in | ADP\n",
      "polynomial | ADJ\n",
      "time | NOUN\n",
      ". | PUNCT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in english_pos_data:\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        print(token.text, \"|\", token.pos_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
